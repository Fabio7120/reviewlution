{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/dataset_3_clean.csv').drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "      <td>nice room 4 experience hotel monaco seattle go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "      <td>unique great stay wonderful time hotel monaco ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "      <td>great stay great stay went seahawk game awesom...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0  nice hotel expensive parking got good deal sta...       4   \n",
       "1  ok nothing special charge diamond member hilto...       2   \n",
       "2  nice rooms not 4* experience hotel monaco seat...       3   \n",
       "3  unique, great stay, wonderful time hotel monac...       5   \n",
       "4  great stay great stay, went seahawk game aweso...       5   \n",
       "\n",
       "                                        review_clean  class1  class2  \n",
       "0  nice hotel expensive parking got good deal sta...       1       0  \n",
       "1  ok nothing special charge diamond member hilto...       0       0  \n",
       "2  nice room 4 experience hotel monaco seattle go...       0       0  \n",
       "3  unique great stay wonderful time hotel monaco ...       2       1  \n",
       "4  great stay great stay went seahawk game awesom...       2       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df drop null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove comments les than x words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(X):\n",
    "    return len(X.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['review_clean'].apply(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['word_count']>9].reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['review_clean'][:12000]\n",
    "X_test = df['review_clean'][12000:20000]\n",
    "\n",
    "y_train = df['rating'][:12000]\n",
    "y_test = df['rating'][12000:20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12720"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(s) for s in X_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorizing und embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "# –– Step #1\n",
    "def convert_sentences(X):\n",
    "    return [sentence.split(' ') for sentence in X]\n",
    "\n",
    "X_train_words = convert_sentences(X_train)\n",
    "X_test_words = convert_sentences(X_test)\n",
    "\n",
    "\n",
    "# –– Step #2\n",
    "word2vec = Word2Vec(sentences=X_train, min_count=10, window=10)\n",
    "\n",
    "\n",
    "# –– Step #3\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "X_train_embed = embedding(word2vec, X_train_words)\n",
    "X_test_embed = embedding(word2vec, X_test_words)\n",
    "\n",
    "\n",
    "# –– Step #4\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 36, 100)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, metrics\n",
    "\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.LSTM(20, return_sequences=True, activation='tanh'))\n",
    "\n",
    "\n",
    "    model.add(layers.Dense(40, activation='relu'))\n",
    "    \n",
    "    \n",
    "    model.add(layers.Dense(20, activation='relu'))\n",
    "\n",
    "    ## output layer\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "\n",
    "\n",
    "    model.compile(loss='mse',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['mae', metrics.RootMeanSquaredError()])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers, metrics\n",
    "\n",
    "def init_model_2():\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(layers.LSTM(20, return_sequences=True, activation='tanh'))\n",
    "#     model.add(layers.LSTM(10, return_sequences=True, activation='tanh'))\n",
    "    model.add(layers.LSTM(10, activation='tanh'))\n",
    "    model.add(layers.Dense(5, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='linear'))\n",
    "    \n",
    "    model.compile(loss='mse', \n",
    "                  optimizer='rmsprop', \n",
    "                  metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model2 = init_model_2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_pad_short = X_train_pad[:500] # These two lines are just to accelerate the cell run\n",
    "# y_train_short = y_train[:500]\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "history = model2.fit(X_train_pad, y_train, \n",
    "          batch_size = 32,\n",
    "          epochs=100,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = model2.evaluate(X_test_pad, y_test, verbose=0)\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"While am generally happy with their service, there is a push to take a considerable discount for a reservation that does not allow cancellations. The standard undiscounted price is about the same as booking directly with the option of cancellations. Using Booking.com is merely a convenience. The discount for forgoing cancellation needs to be comared with the cost of cancellation insurance. Even if one can't use the reservation because of government restrictions the hotels sock it to the customer for far more than their out of pocket costs since at worst they don't have to service the rooms and at best can re-rent them. Bottom line: Don't be taken in by Booking.com's apparently cheap nonrefundable offers.\"\n",
    "sentence2 = \"Great vacation until we tried to travel home. We tried calling and waited more than 2 hours for a callback and then they were unable/unwilling to help us. Stranded for 48 hours because of this company with no help rebooking flights. We are out for hotel, food, and time off work because I was hung up on repeatedly by their customer service department. Once I was finally home, they told me there's nothing they can do for me that they were really sorry all this happened. They were unwilling to make it right, but told me that I could have requested a refund for my flight home if I would have been able to reach them at the time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [sentence1, sentence2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert into tokens\n",
    "tokens = convert_sentences(lst)\n",
    "\n",
    "## convert tokens into vectors\n",
    "vectors = embedding(word2vec, tokens)\n",
    "\n",
    "# padding the vectors\n",
    "vectors_padding = pad_sequences(vectors, dtype='float32', padding='post')\n",
    "\n",
    "## predict\n",
    "prediction = model2.predict(vectors_padding)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_dataset1 = df['review'][20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_dataset1_rating = df['rating'][20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert into tokens\n",
    "tokens = convert_sentences(X_new_dataset1)\n",
    "\n",
    "## convert tokens into vectors\n",
    "vectors = embedding(word2vec, tokens)\n",
    "\n",
    "# padding the vectors\n",
    "vectors_padding = pad_sequences(vectors, dtype='float32', padding='post')\n",
    "\n",
    "## predict\n",
    "prediction = model2.predict(vectors_padding)\n",
    "\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_comp = {'prediction': pred, 'real_score':X_new_dataset1_rating}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame(dct_comp)\n",
    "df_comp.head(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
