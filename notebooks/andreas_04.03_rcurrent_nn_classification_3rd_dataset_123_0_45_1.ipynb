{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../raw_data/dataset_3_clean.csv').drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_clean</th>\n",
       "      <th>class1</th>\n",
       "      <th>class2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>4</td>\n",
       "      <td>nice hotel expensive parking got good deal sta...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>2</td>\n",
       "      <td>ok nothing special charge diamond member hilto...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nice rooms not 4* experience hotel monaco seat...</td>\n",
       "      <td>3</td>\n",
       "      <td>nice room 4 experience hotel monaco seattle go...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>unique, great stay, wonderful time hotel monac...</td>\n",
       "      <td>5</td>\n",
       "      <td>unique great stay wonderful time hotel monaco ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>great stay great stay, went seahawk game aweso...</td>\n",
       "      <td>5</td>\n",
       "      <td>great stay great stay went seahawk game awesom...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  rating  \\\n",
       "0  nice hotel expensive parking got good deal sta...       4   \n",
       "1  ok nothing special charge diamond member hilto...       2   \n",
       "2  nice rooms not 4* experience hotel monaco seat...       3   \n",
       "3  unique, great stay, wonderful time hotel monac...       5   \n",
       "4  great stay great stay, went seahawk game aweso...       5   \n",
       "\n",
       "                                        review_clean  class1  class2  \n",
       "0  nice hotel expensive parking got good deal sta...       1       0  \n",
       "1  ok nothing special charge diamond member hilto...       0       0  \n",
       "2  nice room 4 experience hotel monaco seattle go...       0       0  \n",
       "3  unique great stay wonderful time hotel monaco ...       2       1  \n",
       "4  great stay great stay went seahawk game awesom...       2       1  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['class3'] = df['rating'].map({\n",
    "    1:0,\n",
    "    2:0,\n",
    "    3:0,\n",
    "    4:1,\n",
    "    5:1,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5    9054\n",
       "4    6039\n",
       "3    2184\n",
       "2    1793\n",
       "1    1421\n",
       "Name: rating, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['rating'] != 4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6264618365511038"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df['class3'])/df['class3'].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df drop null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove comments les than x words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_counter(X):\n",
    "    return len(X.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['word_count'] = df['review'].apply(word_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df['word_count']>9].reset_index().drop('index', axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df['review'][:5000]\n",
    "X_test = df['review'][5000:7000]\n",
    "\n",
    "y_train = df['class3'][:5000]\n",
    "y_test = df['class3'][5000:7000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13501"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(s) for s in X_train])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vectorizing und embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# –– Step #1\n",
    "def convert_sentences(X):\n",
    "    return [sentence.split(' ') for sentence in X]\n",
    "\n",
    "X_train_words = convert_sentences(X_train)\n",
    "X_test_words = convert_sentences(X_test)\n",
    "\n",
    "# –– Step #2\n",
    "from gensim.models import Word2Vec\n",
    "word2vec = Word2Vec(sentences=X_train, size=200, min_count=1, window=15)\n",
    "\n",
    "# –– Step #3\n",
    "def embed_sentence(word2vec, sentence):\n",
    "    embedded_sentence = []\n",
    "    for word in sentence:\n",
    "        if word in word2vec.wv:\n",
    "            embedded_sentence.append(word2vec.wv[word])\n",
    "        \n",
    "    return np.array(embedded_sentence)\n",
    "\n",
    "# -- step 4\n",
    "def embedding(word2vec, sentences):\n",
    "    embed = []\n",
    "    \n",
    "    for sentence in sentences:\n",
    "        embedded_sentence = embed_sentence(word2vec, sentence)\n",
    "        embed.append(embedded_sentence)\n",
    "        \n",
    "    return embed\n",
    "\n",
    "\n",
    "X_train_embed = embedding(word2vec, X_train_words)\n",
    "X_test_embed = embedding(word2vec, X_test_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X_train_pad = pad_sequences(X_train_embed, dtype='float32', padding='post')\n",
    "X_test_pad = pad_sequences(X_test_embed, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 200)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pad[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def init_model():\n",
    "    model = Sequential()\n",
    "    model.add(layers.Masking())\n",
    "    model.add(layers.LSTM(20, activation='tanh'))\n",
    "    model.add(layers.Dense(15, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='rmsprop',\n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = init_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis']\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "print(list(api.info()['models'].keys()))\n",
    "\n",
    "\n",
    "word2vec_wiki = api.load(\"glove-wiki-gigaword-50\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-88be99edf173>:16: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if word in word2vec.wv:\n",
      "<ipython-input-37-88be99edf173>:17: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  embedded_sentence.append(word2vec.wv[word])\n"
     ]
    }
   ],
   "source": [
    "X_train_words_2 = convert_sentences(X_train)\n",
    "X_test_words_2 = convert_sentences(X_test)\n",
    "\n",
    "\n",
    "# –– Embed the sentences thanks to the new embedding\n",
    "X_train_embed_2 = embedding(word2vec_wiki, X_train_words_2)\n",
    "X_test_embed_2 = embedding(word2vec_wiki, X_test_words_2)\n",
    "\n",
    "\n",
    "# –– Pad the sentences\n",
    "X_train_pad_2 = pad_sequences(X_train_embed_2, dtype='float32', padding='post')\n",
    "X_test_pad_2 = pad_sequences(X_test_embed_2, dtype='float32', padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "110/110 [==============================] - 108s 959ms/step - loss: 0.6552 - accuracy: 0.5987 - val_loss: 0.5171 - val_accuracy: 0.7673\n",
      "Epoch 2/10\n",
      "110/110 [==============================] - 114s 1s/step - loss: 0.4895 - accuracy: 0.7842 - val_loss: 0.4672 - val_accuracy: 0.8060\n",
      "Epoch 3/10\n",
      "110/110 [==============================] - 129s 1s/step - loss: 0.4586 - accuracy: 0.7967 - val_loss: 0.4186 - val_accuracy: 0.8273\n",
      "Epoch 4/10\n",
      "110/110 [==============================] - 112s 1s/step - loss: 0.3998 - accuracy: 0.8369 - val_loss: 0.3982 - val_accuracy: 0.8333\n",
      "Epoch 5/10\n",
      "110/110 [==============================] - 116s 1s/step - loss: 0.3924 - accuracy: 0.8431 - val_loss: 0.4385 - val_accuracy: 0.8393\n",
      "Epoch 6/10\n",
      "110/110 [==============================] - 112s 1s/step - loss: 0.3772 - accuracy: 0.8480 - val_loss: 0.5798 - val_accuracy: 0.7773\n",
      "Epoch 7/10\n",
      "110/110 [==============================] - 110s 1s/step - loss: 0.3650 - accuracy: 0.8510 - val_loss: 0.4441 - val_accuracy: 0.8147\n",
      "Epoch 8/10\n",
      "110/110 [==============================] - 120s 1s/step - loss: 0.3502 - accuracy: 0.8535 - val_loss: 0.3623 - val_accuracy: 0.8533\n",
      "Epoch 9/10\n",
      "110/110 [==============================] - 113s 1s/step - loss: 0.3377 - accuracy: 0.8660 - val_loss: 0.4483 - val_accuracy: 0.8133\n",
      "Epoch 10/10\n",
      "110/110 [==============================] - 113s 1s/step - loss: 0.3168 - accuracy: 0.8721 - val_loss: 0.4925 - val_accuracy: 0.8053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f79396b8eb0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "es = EarlyStopping(patience=5, restore_best_weights=True)\n",
    "\n",
    "model = init_model()\n",
    "\n",
    "model.fit(X_train_pad_2, y_train, \n",
    "          batch_size = 32,\n",
    "          epochs=10,\n",
    "          validation_split=0.3,\n",
    "          callbacks=[es]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy evaluated on the test set is of 82.150%\n"
     ]
    }
   ],
   "source": [
    "res = model.evaluate(X_test_pad_2, y_test, verbose=0)\n",
    "\n",
    "print(f'The accuracy evaluated on the test set is of {res[1]*100:.3f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5876"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)/len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.636"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_test)/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"While am generally happy with their service, there is a push to take a considerable discount for a reservation that does not allow cancellations. The standard undiscounted price is about the same as booking directly with the option of cancellations. Using Booking.com is merely a convenience. The discount for forgoing cancellation needs to be comared with the cost of cancellation insurance. Even if one can't use the reservation because of government restrictions the hotels sock it to the customer for far more than their out of pocket costs since at worst they don't have to service the rooms and at best can re-rent them. Bottom line: Don't be taken in by Booking.com's apparently cheap nonrefundable offers.\"\n",
    "sentence2 = \"Great vacation until we tried to travel home. We tried calling and waited more than 2 hours for a callback and then they were unable/unwilling to help us. Stranded for 48 hours because of this company with no help rebooking flights. We are out for hotel, food, and time off work because I was hung up on repeatedly by their customer service department. Once I was finally home, they told me there's nothing they can do for me that they were really sorry all this happened. They were unwilling to make it right, but told me that I could have requested a refund for my flight home if I would have been able to reach them at the time.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [sentence1, sentence2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert into tokens\n",
    "tokens = convert_sentences(lst)\n",
    "\n",
    "## convert tokens into vectors\n",
    "vectors = embedding(word2vec_wiki, tokens)\n",
    "\n",
    "# padding the vectors\n",
    "vectors_padding = pad_sequences(vectors, dtype='float32', padding='post')\n",
    "\n",
    "## predict\n",
    "prediction = model.predict(vectors_padding)\n",
    "\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_dataset1 = df['review'][20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new_dataset1_rating = df['rating'][20000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert into tokens\n",
    "tokens = convert_sentences(X_new_dataset1)\n",
    "\n",
    "## convert tokens into vectors\n",
    "vectors = embedding(word2vec_wiki, tokens)\n",
    "\n",
    "# padding the vectors\n",
    "vectors_padding = pad_sequences(vectors, dtype='float32', padding='post')\n",
    "\n",
    "## predict\n",
    "prediction = model.predict(vectors_padding)\n",
    "\n",
    "# prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = prediction.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dct_comp = {'prediction': pred, 'real_score':X_new_dataset1_rating}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame(dct_comp)\n",
    "df_comp.head(60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
