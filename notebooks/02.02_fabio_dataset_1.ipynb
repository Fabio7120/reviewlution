{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1 = pd.read_csv(\"../raw_data/dataset_1.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspecting data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1.info()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping redundant columns"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1 = dataset_1[['Negative_Review', 'Positive_Review', 'Reviewer_Score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning and merging negative and positive reviews"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1[['Negative_Review']] = dataset_1[['Negative_Review']].replace(to_replace=\"No Negative\", value=\"\")\n",
    "\n",
    "dataset_1[['Positive_Review']] = dataset_1[['Positive_Review']].replace(to_replace=\"No Positive\", value=\"\")\n",
    "\n",
    "dataset_1[\"Review_Text\"] = dataset_1['Negative_Review'] + \" \" + dataset_1['Positive_Review']\n",
    "\n",
    "dataset_1 = dataset_1.drop(columns=['Negative_Review', 'Positive_Review'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower case"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1['Review_Text'] = dataset_1['Review_Text'].apply(lambda x: x.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove numbers"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def remove_numbers(text):\n",
    "    text = ''.join(word for word in text if not word.isdigit())\n",
    "    return text\n",
    "\n",
    "dataset_1['Review_Text'] = dataset_1['Review_Text'].apply(remove_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for punctuation in string.punctuation:\n",
    "    dataset_1['Review_Text'] = dataset_1['Review_Text'].replace(punctuation, '') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stopwords"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "stop_words = set(stopwords.words('english')) \n",
    "dataset_1['reviews'] = dataset_1['Review_Text'].map(word_tokenize)\n",
    "dataset_1['reviews'] = dataset_1['reviews'].map(lambda x: [w for w in x if not w in stop_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizing"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatizing(text):\n",
    "    lemmatized = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = lemmatized\n",
    "    text = ' '.join(word for word in text)\n",
    "    return text\n",
    "\n",
    "dataset_1['reviews'] = dataset_1['reviews'].apply(lemmatizing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom scaling and rounding"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1['review_score'] = dataset_1['Reviewer_Score'] / 10\n",
    "\n",
    "dataset_1 = dataset_1.drop(columns=['Review_Text', 'Reviewer_Score'])\n",
    "\n",
    "dataset_1['review_score'] = dataset_1['review_score'].round(decimals=2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Final check\n",
    "dataset_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting to csv"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dataset_1.to_csv('../raw_data/clean_dataset_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------- NEW FILE --------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry made post available via possible site us...</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>real complaint hotel great great location surr...</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>room nice elderly bit difficult room two story...</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>room dirty afraid walk barefoot floor looked c...</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>booked company line showed picture room though...</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515733</th>\n",
       "      <td>trolly staff help take luggage room location</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515734</th>\n",
       "      <td>hotel look like surely breakfast ok got earlie...</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515735</th>\n",
       "      <td>ac useless hot week vienna gave hot air</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515736</th>\n",
       "      <td>room enormous really comfortable believe famil...</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515737</th>\n",
       "      <td>rd floor work free wife staff kind</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>515738 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  reviews  review_score\n",
       "0       angry made post available via possible site us...          0.29\n",
       "1       real complaint hotel great great location surr...          0.75\n",
       "2       room nice elderly bit difficult room two story...          0.71\n",
       "3       room dirty afraid walk barefoot floor looked c...          0.38\n",
       "4       booked company line showed picture room though...          0.67\n",
       "...                                                   ...           ...\n",
       "515733       trolly staff help take luggage room location          0.70\n",
       "515734  hotel look like surely breakfast ok got earlie...          0.58\n",
       "515735            ac useless hot week vienna gave hot air          0.25\n",
       "515736  room enormous really comfortable believe famil...          0.88\n",
       "515737                 rd floor work free wife staff kind          0.83\n",
       "\n",
       "[515738 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../raw_data/clean_dataset_1.csv\", index_col=0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove less than 10 words (To Do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>angry made post available via possible site us...</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>real complaint hotel great great location surr...</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>room nice elderly bit difficult room two story...</td>\n",
       "      <td>0.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>room dirty afraid walk barefoot floor looked c...</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>booked company line showed picture room though...</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299735</th>\n",
       "      <td>noisy night air causing loud banging heating p...</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299736</th>\n",
       "      <td>put fotos cinde room see booking location give...</td>\n",
       "      <td>0.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299737</th>\n",
       "      <td>wifi location tea coffee room rather cheap far...</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299738</th>\n",
       "      <td>breakfast excelent lot fress fruit hotel good ...</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299739</th>\n",
       "      <td>free parking room another building need exit b...</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>299740 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  reviews  review_score\n",
       "0       angry made post available via possible site us...          0.29\n",
       "1       real complaint hotel great great location surr...          0.75\n",
       "2       room nice elderly bit difficult room two story...          0.71\n",
       "3       room dirty afraid walk barefoot floor looked c...          0.38\n",
       "4       booked company line showed picture room though...          0.67\n",
       "...                                                   ...           ...\n",
       "299735  noisy night air causing loud banging heating p...          0.63\n",
       "299736  put fotos cinde room see booking location give...          0.54\n",
       "299737  wifi location tea coffee room rather cheap far...          0.58\n",
       "299738  breakfast excelent lot fress fruit hotel good ...          1.00\n",
       "299739  free parking room another building need exit b...          0.67\n",
       "\n",
       "[299740 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['length'] = data['reviews'].apply(lambda x: len(word_tokenize(str(x))))\n",
    "data.drop(data[data['length'] < 11].index, inplace=True)\n",
    "data.drop(columns=['length'], inplace=True)\n",
    "data.reset_index(drop=True, inplace=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WARNING - TOO MANY DROPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(299740, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Words with numbers (To Do - DONT DO - Checked with BEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def remove_words_w_numbers(text):\n",
    "#     # Tokenizing\n",
    "#     text_tokenized = word_tokenize(text)\n",
    "#     text = [str(word) for word in text_tokenized] # if not word.isdigit()] \n",
    "#     text = [list(word) for word in text] # if not letter.isdigit()]\n",
    "# #     text = ' '.join([word for word in text])\n",
    "# #     text = ' '.join([word for word in text])\n",
    "#     return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_words_w_numbers(str(data['reviews'][4] + \" 3rd\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer: Bag of words - Model: LinearRegression"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "X_bow = vectorizer.fit_transform(data['reviews'][:10000])\n",
    "y = data['review_score'][:10000]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "model = LinearRegression()\n",
    "\n",
    "result = cross_validate(model,X_bow,y)\n",
    "\n",
    "result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer: Tf-Idf - Model: LinearRegression (max_features=50) (0.21)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(max_features=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf_idf_vectorizer.fit_transform(data['reviews'][:10000])\n",
    "y = data['review_score'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 50), (2000, 50), (8000,), (2000,))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hold out \n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names()), y, test_size=0.2)\n",
    "\n",
    "#check\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2087041806052611"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "result = cross_validate(model,X_test,y_test)\n",
    "\n",
    "result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loop - max_features=50  (pipiline)  - grid search (50, 100 , 200)  / try different alphas"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Create Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('linear_regression', LinearRegression()),\n",
    "])\n",
    "\n",
    "# pipeline.get_params()\n",
    "\n",
    "\n",
    "\n",
    "# Set parameters to search (model and vectorizer)\n",
    "parameters = {\n",
    "    'tfidf__max_features': (50, 100, 200),\n",
    "    }\n",
    "#     'nb__alpha': (0.1,0.5,1,3),}\n",
    "\n",
    "\n",
    "# Perform grid search on pipeline\n",
    "grid_search = GridSearchCV(pipeline, parameters, n_jobs=-1, \n",
    "                           verbose=1, scoring = \"r2\", \n",
    "                           refit=True, cv=5)\n",
    "\n",
    "grid_search.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer: Tf-Idf - Model: LinearRegression (max_features=200) (0.38)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(max_features=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf_idf_vectorizer.fit_transform(data['reviews'][:10000])\n",
    "y = data['review_score'][:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 200), (2000, 200), (8000,), (2000,))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hold out \n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names()), y, test_size=0.2)\n",
    "\n",
    "#check\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37104277075166936"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "result = cross_validate(model,X_test,y_test)\n",
    "\n",
    "result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer: Tf-Idf (max_features=200) - Model: Lasso (-0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0033445541332157713"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "model = Lasso()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "result = cross_validate(model,X_test,y_test)\n",
    "\n",
    "result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "lasso_result = cross_validate(pipeline_tfidf_l1_lasso, X_test, y_test, cv=5, scoring='r2')\n",
    "lasso_result"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import learning_curve\n",
    "#Learning Curves\n",
    "train_sizes = [25,50,75,100,250,500,750,1000,1150]\n",
    "# Get train scores (R2), train sizes, and validation scores using `learning_curve`\n",
    "train_sizes, train_scores, test_scores = learning_curve(\n",
    "    estimator=pipeline_tfidf_l1_lasso, X=X_test, y=y_test, train_sizes=train_sizes, cv=5)\n",
    "\n",
    "# Take the mean of cross-validated train scores and validation scores\n",
    "train_scores_mean = np.mean(train_scores, axis=1)\n",
    "test_scores_mean = np.mean(test_scores, axis=1)\n",
    "plt.plot(train_sizes, train_scores_mean, label = 'Training score')\n",
    "plt.plot(train_sizes, test_scores_mean, label = 'Test score')\n",
    "#plt.ylabel('r2 score', fontsize = 14)\n",
    "#plt.xlabel('Training set size', fontsize = 14)\n",
    "plt.title('Learning curves', fontsize = 18, y = 1.03)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer: Tf-Idf - Model: Random Forest (0.31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### (0.31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.32599855, 0.28929107, 0.37346665, 0.32872847, 0.25845931])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3151888082797575"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test score\n",
    "cv_results.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.317347755547485"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(max_depth=80, min_samples_split=3, min_samples_leaf=2, n_estimators=200)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2856400462332994"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(max_depth=100, min_samples_split=20, min_samples_leaf=10, n_estimators=200)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DO THEM ON GOOGLE COLAB - TAKES TOOOOO LONG\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Random search \n",
    "random_search = RandomizedSearchCV(\n",
    "    model, \n",
    "    param_distributions ={\n",
    "        'max_depth': randint(10,100),\n",
    "        'min_samples_split' : randint(2,20),\n",
    "        'min_samples_leaf': [1, 2, 5, 10],\n",
    "        'n_estimators': [100, 200, 300, 1000]},\n",
    "    cv=5,\n",
    "    n_iter = 20,\n",
    "    scoring='r2',\n",
    "    )\n",
    "\n",
    "random_search.fit(X,y)\n",
    "random_search.best_estimator_, random_search.best_score_"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DO THEM ON GOOGLE COLAB - TAKES TOOOOO LONG\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Random search \n",
    "random_search = RandomizedSearchCV(\n",
    "    model, \n",
    "    param_distributions ={\n",
    "        'max_depth': randint(1,35),\n",
    "        'min_samples_split' : randint(2,20)},\n",
    "    cv=5,\n",
    "    n_iter = 50,\n",
    "    scoring='r2',\n",
    "    )\n",
    "\n",
    "random_search.fit(X,y)\n",
    "random_search.best_estimator_, random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt \n",
    "# from sklearn.model_selection import learning_curve\n",
    "# #Learning Curves\n",
    "# train_sizes = [25,50,75,100,250,500,750,1000,1150]\n",
    "# # Get train scores (R2), train sizes, and validation scores using `learning_curve`\n",
    "# train_sizes, train_scores, test_scores = learning_curve(\n",
    "#     estimator=pipeline_tfidf_l1_lasso, X=data['reviews'], y=y, train_sizes=train_sizes, cv=5)\n",
    "\n",
    "# # Take the mean of cross-validated train scores and validation scores\n",
    "# train_scores_mean = np.mean(train_scores, axis=1)\n",
    "# test_scores_mean = np.mean(test_scores, axis=1)\n",
    "# plt.plot(train_sizes, train_scores_mean, label = 'Training score')\n",
    "# plt.plot(train_sizes, test_scores_mean, label = 'Test score')\n",
    "# #plt.ylabel('r2 score', fontsize = 14)\n",
    "# #plt.xlabel('Training set size', fontsize = 14)\n",
    "# plt.title('Learning curves', fontsize = 18, y = 1.03)\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer: Tf-Idf - Model: KNN (0.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13323591069381152"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "model = KNeighborsRegressor()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorizer: Tf-Idf - SVM - Linear (0.37)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3594117159885309"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='linear')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.350323186253943"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel='linear', gamma=3, C=10)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Version 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2462946823187738"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel='poly')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3876106519241459"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3736975954943555"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel='rbf', gamma=0.15, C=20)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.24889806043884904"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel='sigmoid')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 5 - SVR(kernel='linear') - RandomSearch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DO THEM ON GOOGLE COLAB - TAKES TOOOOO LONG\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Random search \n",
    "random_search = RandomizedSearchCV(\n",
    "    SVR(kernel='linear'), \n",
    "    param_distributions ={\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1, 5]},\n",
    "    cv=5,\n",
    "    n_iter = 20,\n",
    "    scoring='r2',\n",
    "    )\n",
    "\n",
    "random_search.fit(X_train,y_train)\n",
    "random_search.best_estimator_, random_search.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Version 6 - SVR(kernel='rbf') - RandomSearch "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# DO THEM ON GOOGLE COLAB - TAKES TOOOOO LONG\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "# Random search \n",
    "random_search = RandomizedSearchCV(\n",
    "    SVR(kernel='rbf'), \n",
    "    param_distributions ={\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10],\n",
    "        'gamma': [0.001, 0.01, 0.1, 1, 5]},\n",
    "    cv=5,\n",
    "    n_iter = 20,\n",
    "    scoring='r2',\n",
    "    )\n",
    "\n",
    "random_search.fit(X_train,y_train)\n",
    "random_search.best_estimator_, random_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  20.000 DataPoints and max_features=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16000, 500), (4000, 500), (16000,), (4000,))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tf_idf_vectorizer = TfidfVectorizer(max_features=500)\n",
    "\n",
    "X = tf_idf_vectorizer.fit_transform(data['reviews'][:20000])\n",
    "y = data['review_score'][:20000]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Hold out \n",
    "X_train, X_test, y_train, y_test = train_test_split(pd.DataFrame(X.toarray(),columns = tf_idf_vectorizer.get_feature_names()), y, test_size=0.2)\n",
    "\n",
    "#check\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: LinearRegression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34630050416534763"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "result = cross_validate(model,X_test,y_test)\n",
    "\n",
    "result['test_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: Random Forest  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30810832845252856"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestRegressor(n_estimators=100)\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: SVM - Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3479263037658146"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "model = SVR(kernel='linear')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: SVM - rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36662833287129154"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVR(kernel='rbf')\n",
    "model.fit(X_train,y_train)\n",
    "\n",
    "cv_results = cross_val_score(model, X_test,y_test, cv=5, scoring='r2').mean()\n",
    "cv_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "\n",
    "# # Export pipeline as pickle file\n",
    "# with open(\"pipeline.pkl\", \"wb\") as file:\n",
    "#     pickle.dump(best_pipeline, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
