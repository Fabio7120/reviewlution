{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def get_data(nrows=1000):\n",
    "    '''returns a DataFrame with nrows from downloaded Keggle csv in raw_data folder'''\n",
    "    dataset_1 = pd.read_csv(\"../raw_data/dataset_1.csv\", nrows=nrows)\n",
    "    df = dataset_1.copy()\n",
    "    return df\n",
    "\n",
    "\n",
    "def clean_data(df):\n",
    "    '''returns cleaned DataFrame'''\n",
    "    \n",
    "    # dropping redundant columns\n",
    "    df_clean = df[['Negative_Review', 'Positive_Review', 'Reviewer_Score']]\n",
    "\n",
    "    # Cleaning, merging and renaming negative and positive reviews\n",
    "    df_clean.loc[:,'Negative_Review'] = df_clean.loc[:,'Negative_Review'].replace(to_replace=\"No Negative\", value=\"\")\n",
    "    df_clean.loc[:,'Positive_Review'] = df_clean.loc[:,'Positive_Review'].replace(to_replace=\"No Positive\", value=\"\")\n",
    "    df_clean.loc[:,\"reviews\"] = df_clean.loc[:,'Negative_Review'] + \" \" + df_clean.loc[:,'Positive_Review']\n",
    "    df_clean.loc[:,\"review_score\"] = df_clean.loc[:,'Reviewer_Score']\n",
    "    df_clean = df_clean.drop(columns=['Negative_Review', 'Positive_Review', 'Reviewer_Score'])\n",
    "\n",
    "    # Remove reviews with less than 10 words (or signs)\n",
    "    df_clean.loc[:,'length'] = df_clean['reviews'].apply(lambda x: len(word_tokenize(str(x))))\n",
    "    df_clean.drop(df_clean[df_clean['length'] < 11].index, inplace=True)\n",
    "    df_clean.drop(columns=['length'], inplace=True)\n",
    "    df_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "def custom_stopwords():\n",
    "    \"\"\"create custom stopwords list excluding negative words\"\"\"\n",
    "    negative_words = ['no',\n",
    "    'nor',\n",
    "    'not',\n",
    "    \"don't\",\n",
    "    'should',\n",
    "    \"should've\",\n",
    "    'aren',\n",
    "    \"aren't\",\n",
    "    'couldn',\n",
    "    \"couldn't\",\n",
    "    'didn',\n",
    "    \"didn't\",\n",
    "    'doesn',\n",
    "    \"doesn't\",\n",
    "    'hadn',\n",
    "    \"hadn't\",\n",
    "    'hasn',\n",
    "    \"hasn't\",\n",
    "    'haven',\n",
    "    \"haven't\",\n",
    "    'isn',\n",
    "    \"isn't\",\n",
    "    \"wasn't\",\n",
    "    'weren',\n",
    "    \"weren't\",\n",
    "    'won',\n",
    "    \"won't\",\n",
    "    'wouldn',\n",
    "    \"wouldn't\"]\n",
    "\n",
    "    custom_stopwords = [x for x in stopwords.words('english') if x not in negative_words]\n",
    "\n",
    "    return custom_stopwords\n",
    "\n",
    "\n",
    "def clean_for_nlp(text):\n",
    "    \"\"\" preprocess review text data for nlp analysis \"\"\"\n",
    "    # Lower case\n",
    "    text = ''.join(text)\n",
    "    text = text.lower()\n",
    "    # Remove numbers\n",
    "    text = ''.join(word for word in text if not word.isdigit())\n",
    "    # Remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    # Remove stopwords\n",
    "    text = word_tokenize(text)\n",
    "    stopwords = custom_stopwords()\n",
    "    text = [w for w in text if not w in stopwords]\n",
    "    # Lemmatizing\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text]\n",
    "    text = ' '.join(word for word in text)\n",
    "\n",
    "    return(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextProcessor(BaseEstimator, TransformerMixin):\n",
    "    \"\"\" Custom Transformer for text to nlp-preprocessed  \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.vectorizer = CountVectorizer(dtype=np.int32)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X_transformed = list(map(clean_for_nlp, X['reviews']))\n",
    "        self.vectorizer.fit(X_transformed)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        X_transformed = list(map(clean_for_nlp, X['reviews']))\n",
    "        X_vectorized = self.vectorizer.transform(X_transformed).toarray()\n",
    "\n",
    "        return pd.DataFrame(X_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from termcolor import colored\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    def __init__(self, X, y):\n",
    "        \"\"\"\n",
    "            X: pandas DataFrame\n",
    "            y: pandas Series\n",
    "        \"\"\"\n",
    "        self.pipeline = None\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "   \n",
    "    def set_pipeline(self):\n",
    "        \"\"\"defines the pipeline as a class attribute\"\"\"\n",
    "        nlp_transformer = Pipeline([('text_preprocessor', TextProcessor())])\n",
    "\n",
    "        preproc_pipe = ColumnTransformer([\n",
    "        ('nlp_transformer', nlp_transformer, [\"reviews\"])], remainder=\"drop\")\n",
    "\n",
    "        self.pipeline = Pipeline([('preproc', preproc_pipe), ('linear_model', LinearRegression())])\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        self.set_pipeline()\n",
    "        self.pipeline.fit(self.X, self.y)\n",
    "        print(\"trained model\")\n",
    "\n",
    "\n",
    "    def evaluate(self):\n",
    "        \"\"\"evaluates the pipeline and returns r2\"\"\"\n",
    "        pass\n",
    "        #cv = cross_val_score(self.pipeline, self.X, self.y, cv=5, scoring='r2').mean()\n",
    "\n",
    "        #return cv\n",
    "\n",
    "\n",
    "    def save_model(self):\n",
    "        \"\"\"Save the model into a .joblib format\"\"\"\n",
    "        joblib.dump(self.pipeline, 'model.joblib')\n",
    "        print(colored(\"model.joblib saved locally\", \"green\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kili/.pyenv/versions/3.8.6/envs/reviewlution/lib/python3.8/site-packages/pandas/core/indexing.py:1676: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_single_column(ilocs[0], value, pi)\n",
      "/home/kili/.pyenv/versions/3.8.6/envs/reviewlution/lib/python3.8/site-packages/pandas/core/indexing.py:1597: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[key] = value\n"
     ]
    }
   ],
   "source": [
    "N = 1000\n",
    "df = get_data(nrows=N)\n",
    "df = clean_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>review_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I am so angry that i made this post available...</td>\n",
       "      <td>2.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No real complaints the hotel was great great...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rooms are nice but for elderly a bit difficul...</td>\n",
       "      <td>7.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>My room was dirty and I was afraid to walk ba...</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You When I booked with your company on line y...</td>\n",
       "      <td>6.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  review_score\n",
       "0   I am so angry that i made this post available...           2.9\n",
       "1    No real complaints the hotel was great great...           7.5\n",
       "2   Rooms are nice but for elderly a bit difficul...           7.1\n",
       "3   My room was dirty and I was afraid to walk ba...           3.8\n",
       "4   You When I booked with your company on line y...           6.7"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y = df[\"review_score\"]\n",
    "X = df.drop(\"review_score\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(X=X_train, y=y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "648     9.2\n",
       "257     7.5\n",
       "591     7.1\n",
       "517    10.0\n",
       "199     6.7\n",
       "       ... \n",
       "162     5.0\n",
       "754     7.5\n",
       "493    10.0\n",
       "56      7.1\n",
       "559     5.4\n",
       "Name: review_score, Length: 734, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained model\n"
     ]
    }
   ],
   "source": [
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc = trainer.pipeline.named_steps['preproc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = preproc.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_model = trainer.pipeline.named_steps['linear_model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(linear_model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 9.2,  7.5,  7.1, 10. ,  6.7,  6.7,  7.5,  5.8,  8.8,  7.9,  8.8,\n",
       "        9.2, 10. , 10. ,  9.6,  7.5,  7.9,  3.8,  8.3,  7.9,  7.1,  7.9,\n",
       "       10. ,  9.2, 10. ,  6.3,  9.6, 10. ,  6.3,  9.2,  8.3,  4.6,  9.2,\n",
       "        7.9, 10. , 10. ,  7.9,  7.9,  8.8, 10. ,  7.5,  8.8, 10. ,  9.2,\n",
       "        3.8,  7.1,  9.2,  9.2,  7.9,  5. ,  8.3,  8.8,  9.2,  9.2,  7.9,\n",
       "        5.8,  9.6, 10. ,  8.8,  9.6,  5.8,  9.6,  7.5,  9.2,  9.2, 10. ,\n",
       "       10. ,  7.9,  2.9,  9.6,  4.6,  8.8,  5.8,  4.2,  8.8,  8.3, 10. ,\n",
       "        9.2, 10. ,  8.3,  6.3, 10. ,  8.8,  5. ,  8.3,  9.2,  9.2,  7.1,\n",
       "        4.6,  8.3,  7.5,  7.1,  9.2,  5.8,  7.5,  6.3,  5.8, 10. ,  7.9,\n",
       "        8.8,  9.2,  6.7,  6.3,  6.7,  8.8,  7.1,  7.9,  8.8,  8.8,  7.1,\n",
       "        8.3, 10. ,  7.9,  7.5,  9.6,  9.2,  9.6,  6.7,  7.5,  9.6,  9.2,\n",
       "        7.5,  5.8,  9.6,  9.6,  8.8,  8.8,  9.2,  6.7,  7.9,  7.1,  4.6,\n",
       "       10. ,  5.8, 10. ,  5.8,  7.5,  9.6, 10. ,  8.8,  7.5, 10. ,  7.9,\n",
       "        6.3,  6.7,  7.1, 10. ,  7.5, 10. ,  8.3,  4.6, 10. ,  4.2, 10. ,\n",
       "        2.9,  9.6,  9.6, 10. ,  7.1,  7.9,  5.4,  9.2, 10. ,  9.6,  9.2,\n",
       "        8.3,  7.1,  9.2,  6.3,  7.1,  6.3,  4.2,  8.8,  6.7,  8.3, 10. ,\n",
       "        5.4, 10. ,  8.8,  9.6, 10. ,  8.3,  5.8, 10. ,  7.9, 10. ,  9.6,\n",
       "        9.6,  9.6,  7.9,  3.8,  9.2,  6.3, 10. ,  9.6,  5.8, 10. ,  9.6,\n",
       "        9.6,  8.3,  9.6, 10. ,  9.2,  4.6,  8.8, 10. ,  7.9, 10. ,  4.2,\n",
       "       10. ,  5. ,  9.6,  6.3,  8.3,  9.6,  7.1,  6. ,  9.6,  9.2,  4.2,\n",
       "        2.5,  9.2,  5. , 10. ,  7.1,  8.8,  9.2,  7.1,  9.6,  7.9,  8.8,\n",
       "       10. ,  6.7,  9.6,  9.6, 10. ,  9.6,  6.7,  9.2, 10. ,  5.4,  7.5,\n",
       "        8.3, 10. ,  8.3,  7.1,  7.5,  9.6, 10. ,  9.6,  7.1,  9.2, 10. ,\n",
       "        8.3,  9.2,  9.6,  7.9, 10. ,  7.5,  5.8,  6.7,  4.2,  7.9,  8.8,\n",
       "        9.6,  7.5, 10. ,  5.4,  9.6,  8.3,  7.9, 10. ,  7.9, 10. ,  7.1,\n",
       "        8.8,  6.3,  8.3,  7.5,  4.6,  6.3,  8.8,  7.9,  5.4,  3.1,  5.4,\n",
       "       10. ,  5.5,  7.9,  9.2,  5.8,  7.1,  9.6,  9.6,  5. ,  7.5,  9.2,\n",
       "       10. ,  9.6,  7.1,  9.6,  8.3,  8.3,  7.9,  8.3,  9.2,  9.6,  8.3,\n",
       "       10. ,  2.9,  9.6,  8.8,  3.3, 10. ,  9.6,  6.7,  3.8,  5.8,  5. ,\n",
       "        7.9,  7.5,  7.5,  7.5,  7.1,  5. ,  9.2,  9.2,  9.2,  9.2, 10. ,\n",
       "        9.2,  3.8,  9.6, 10. ,  7.5,  7.5,  7.9,  6.7, 10. ,  5. ,  8.8,\n",
       "        9.6,  7.9,  8.3,  7.1,  6.3,  5.4,  9.6,  7.1,  9.6, 10. ,  9.6,\n",
       "       10. ,  7.9,  7.5,  7.5,  9.2, 10. ,  7.1,  7.1,  7.9,  9.6,  8.3,\n",
       "        6.7,  5.8,  5. ,  6.5,  7.5, 10. ,  9.2,  6.7,  9.2, 10. , 10. ,\n",
       "        8.8,  3.3,  8.3,  8.8,  7.9,  8.8, 10. ,  4.2,  7.5,  7.1,  8.8,\n",
       "        6.3, 10. ,  9.2,  8.8,  5.8,  8.3,  9.2, 10. ,  8.3,  7.1,  9.6,\n",
       "        7.9,  4.2,  7.5,  7.5,  9.2,  8.8,  9.2,  9.5,  8.8,  9.2, 10. ,\n",
       "        9.2,  5. ,  6.7, 10. ,  9.6,  7.1,  9.2,  3.3,  8.8,  6.3, 10. ,\n",
       "       10. ,  9.2,  6.7,  7.9,  6.3,  9.6,  8.8,  6. ,  7.9, 10. , 10. ,\n",
       "        9.6, 10. ,  7.5,  9.2,  7.5,  8.3,  9.2,  9.2,  8.8,  9.6,  5.8,\n",
       "       10. ,  8.3,  7.1,  5.4, 10. , 10. ,  8.3,  9.2,  9.6,  9.6,  8.8,\n",
       "       10. , 10. ,  8.3, 10. ,  7.1, 10. ,  8.3, 10. ,  9.6,  5.4,  6.3,\n",
       "        5.4,  7.1, 10. ,  8.3,  6.3,  7.1,  9.6,  9.6,  9.2,  5.5,  9.2,\n",
       "        3.3,  8.3,  4.6,  7.9,  9.6,  6.7,  9.2,  9.6,  4.6,  7.9,  8.3,\n",
       "       10. , 10. , 10. ,  9.6,  6.3,  9.2, 10. , 10. ,  8.3, 10. ,  8.3,\n",
       "       10. ,  9.2,  5.8, 10. ,  6.7,  9.6,  8.3,  9.6, 10. ,  8.8,  9.6,\n",
       "        8.3, 10. ,  9.6,  9.6, 10. ,  7.9,  8.3,  9.6,  8.3,  7.1,  7.5,\n",
       "       10. ,  7.5,  9.2,  9.6,  7.5,  8.8,  6.7, 10. ,  8.3, 10. ,  5.8,\n",
       "        9.2,  8.8,  7.9, 10. ,  8.3,  8.3, 10. ,  4.6,  5. , 10. ,  6.3,\n",
       "        7.5, 10. ,  6.7, 10. ,  8.3,  9.6,  9.6,  9.6,  7.1,  9.2,  8.3,\n",
       "       10. , 10. ,  9.2,  7.5, 10. , 10. ,  9.2,  9.6,  7.1, 10. ,  7.5,\n",
       "        7.1,  7.1,  9.6, 10. ,  8.8, 10. ,  8.3,  8.8, 10. , 10. ,  9.2,\n",
       "        9.6,  8.8,  9.6,  9.6,  5.8,  8.3,  7.1, 10. ,  7.5,  7.1,  8.8,\n",
       "        7.5,  9.2,  9.2,  7.5, 10. ,  7.9, 10. ,  8.8,  7.5,  8.8,  8.8,\n",
       "        9.6,  5.4,  7.5,  7.9,  9.6,  5.4,  6.7,  7.1,  8.3,  7.5,  9.2,\n",
       "        8.3,  8.3,  5.8,  8.3,  5.4,  8.3, 10. ,  5.4,  8.8, 10. ,  8.8,\n",
       "        9.5,  6.3,  9.6,  9.2,  9.2,  8.8,  7.1,  7.1,  9.6, 10. , 10. ,\n",
       "        5. , 10. ,  9.2,  7.9, 10. ,  8.8,  9.6,  9.2,  8.8,  7.9,  7.9,\n",
       "        8.3,  8.3,  6.7,  8.3,  7.9,  8.8, 10. , 10. ,  7.9,  8.8,  5.4,\n",
       "        6.7,  8.8, 10. ,  8.8,  9.2,  7.5, 10. ,  6.3,  4.2,  9.6,  9.2,\n",
       "       10. ,  6.7,  9.2,  9.2,  9.2,  8.8,  6.3,  5.4, 10. ,  8.8,  9.6,\n",
       "       10. ,  8.8,  9.6,  9.6,  5. ,  7.9,  6.7,  7.9,  4.2, 10. , 10. ,\n",
       "        9.2,  8.8,  7.1,  9.6,  9.2,  9.6,  7.9,  8.8,  8.8, 10. ,  7.5,\n",
       "        9.6, 10. ,  5.4, 10. ,  4.6,  7.9,  9.2,  7.5,  9.6,  6.3,  8.8,\n",
       "        8.8,  7.1,  9.6,  9.2,  6.7,  9.2, 10. ,  7.1,  8.3,  9.2, 10. ,\n",
       "        9.2,  8.3,  7.9,  9.2, 10. ,  9.6,  7.5,  8.3,  9.6,  8.8,  8.3,\n",
       "        9.2,  8.3,  8.3,  5. ,  7.5, 10. ,  7.1,  5.4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.pipeline.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\"reviews\": [\"hi my name is Nizar and I'm the superstar around\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame({\"reviews\": [\"hi my name is Kilian\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7.74046862])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.pipeline.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.pipeline.predict(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
